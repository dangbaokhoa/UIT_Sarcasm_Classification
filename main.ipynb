{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import clip\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>724743746f3fe695cd93cab67abf47f31348dd46e1d6e8...</td>\n",
       "      <td>Biển miền Trung nước đẹp nhỉ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7413</th>\n",
       "      <td>92d5d63ece4471fa20fda5a504b841f17eaee8172de711...</td>\n",
       "      <td>Chắc là nắc cụt rồi\\n#phetphaikhong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>abadbf508db12242d4f00f69ac690305e91dc5d8ad0c07...</td>\n",
       "      <td>Nhiều khi ta muốn ta được thiếu nợ\\nĐể khi đi ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5816</th>\n",
       "      <td>84a61e90daadb2297888d685299e25a00a03a91515059b...</td>\n",
       "      <td>Phi công này 1 người lái thôi, ai đụng vào là ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>cf50dca40e9196eb443a4b33db60c17c5ad2da69726aab...</td>\n",
       "      <td>Ủy ban Nhân dân thành phố Đà Nẵng vừa có văn b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  \\\n",
       "464   724743746f3fe695cd93cab67abf47f31348dd46e1d6e8...   \n",
       "7413  92d5d63ece4471fa20fda5a504b841f17eaee8172de711...   \n",
       "3808  abadbf508db12242d4f00f69ac690305e91dc5d8ad0c07...   \n",
       "5816  84a61e90daadb2297888d685299e25a00a03a91515059b...   \n",
       "1632  cf50dca40e9196eb443a4b33db60c17c5ad2da69726aab...   \n",
       "\n",
       "                                                caption  label  \n",
       "464                        Biển miền Trung nước đẹp nhỉ      3  \n",
       "7413                Chắc là nắc cụt rồi\\n#phetphaikhong      3  \n",
       "3808  Nhiều khi ta muốn ta được thiếu nợ\\nĐể khi đi ...      0  \n",
       "5816  Phi công này 1 người lái thôi, ai đụng vào là ...      3  \n",
       "1632  Ủy ban Nhân dân thành phố Đà Nẵng vừa có văn b...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('vimmsd-warmup.json')\n",
    "df = df.T\n",
    "df.head()\n",
    "\n",
    "label_mapping = {\n",
    "    'not-sarcasm': 0,\n",
    "    'image-sarcasm': 1,\n",
    "    'text-sarcasm': 2,\n",
    "    'multi-sarcasm': 3\n",
    "}\n",
    "\n",
    "df['label'] = df['label'].map(label_mapping)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lấy text từ image sử dụng easyOCR (language: vietnam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['vi'], gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')\n",
    "phobert_model = AutoModel.from_pretrained('vinai/phobert-base')\n",
    "\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_image(image_path, phase):\n",
    "    image_path = \"./image/\" + phase + '/' + image_path\n",
    "    result = reader.readtext(image_path)\n",
    "    text = ' '.join([res[1] for res in result])\n",
    "    return text\n",
    "\n",
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = phobert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "def concat_tensors(row):\n",
    "    return torch.cat((row['encoded_caption'], row['encoded_extracted_text']), dim=1)\n",
    "\n",
    "def encode_image(image_path, phase):\n",
    "    image_path = \"./image/\" + phase + \"/\" + image_path\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)  # Tiền xử lý ảnh\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(image)\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Visual Studio Code\\Final_AI\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_caption</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>encoded_extracted_text</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>encoded_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>724743746f3fe695cd93cab67abf47f31348dd46e1d6e8...</td>\n",
       "      <td>Biển miền Trung nước đẹp nhỉ</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(-0.3261), tensor(0.1561), tensor(-0.0...</td>\n",
       "      <td>VỢ CHỔNG THUỶ TIÊN, CÔNG VINH ĐI CHOI PHÚ QUỐC...</td>\n",
       "      <td>[[tensor(-0.2914), tensor(0.2022), tensor(-0.1...</td>\n",
       "      <td>[[tensor(-0.3261), tensor(0.1561), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.2019, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7413</th>\n",
       "      <td>92d5d63ece4471fa20fda5a504b841f17eaee8172de711...</td>\n",
       "      <td>Chắc là nắc cụt rồi\\n#phetphaikhong</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(-0.1268), tensor(-0.0320), tensor(-0....</td>\n",
       "      <td>Jz mấy má? 29 phút trước Học lý 12 không hiểu ...</td>\n",
       "      <td>[[tensor(-0.1801), tensor(0.1206), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.1268), tensor(-0.0320), tensor(-0....</td>\n",
       "      <td>[[tensor(-0.1495, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>abadbf508db12242d4f00f69ac690305e91dc5d8ad0c07...</td>\n",
       "      <td>Nhiều khi ta muốn ta được thiếu nợ\\nĐể khi đi ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.1112), tensor(0.0278), tensor(-0.0...</td>\n",
       "      <td></td>\n",
       "      <td>[[tensor(0.1059), tensor(0.6111), tensor(-0.26...</td>\n",
       "      <td>[[tensor(-0.1112), tensor(0.0278), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.0428, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5816</th>\n",
       "      <td>84a61e90daadb2297888d685299e25a00a03a91515059b...</td>\n",
       "      <td>Phi công này 1 người lái thôi, ai đụng vào là ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(0.0312), tensor(0.0544), tensor(-0.21...</td>\n",
       "      <td>ĐÃ BlẾT ĐUỢC LÍ DO LỆ KWEEN KHÔNG UA TRANG PARIS</td>\n",
       "      <td>[[tensor(-0.0723), tensor(0.1501), tensor(-0.2...</td>\n",
       "      <td>[[tensor(0.0312), tensor(0.0544), tensor(-0.21...</td>\n",
       "      <td>[[tensor(-0.0614, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>cf50dca40e9196eb443a4b33db60c17c5ad2da69726aab...</td>\n",
       "      <td>Ủy ban Nhân dân thành phố Đà Nẵng vừa có văn b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.0825), tensor(0.1394), tensor(-0.0...</td>\n",
       "      <td>Đà Nẵng: Cẩu Rông dừng phun cầu sông Hàn không...</td>\n",
       "      <td>[[tensor(-0.0106), tensor(0.2360), tensor(-0.2...</td>\n",
       "      <td>[[tensor(-0.0825), tensor(0.1394), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.1697, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  \\\n",
       "464   724743746f3fe695cd93cab67abf47f31348dd46e1d6e8...   \n",
       "7413  92d5d63ece4471fa20fda5a504b841f17eaee8172de711...   \n",
       "3808  abadbf508db12242d4f00f69ac690305e91dc5d8ad0c07...   \n",
       "5816  84a61e90daadb2297888d685299e25a00a03a91515059b...   \n",
       "1632  cf50dca40e9196eb443a4b33db60c17c5ad2da69726aab...   \n",
       "\n",
       "                                                caption  label  \\\n",
       "464                        Biển miền Trung nước đẹp nhỉ      3   \n",
       "7413                Chắc là nắc cụt rồi\\n#phetphaikhong      3   \n",
       "3808  Nhiều khi ta muốn ta được thiếu nợ\\nĐể khi đi ...      0   \n",
       "5816  Phi công này 1 người lái thôi, ai đụng vào là ...      3   \n",
       "1632  Ủy ban Nhân dân thành phố Đà Nẵng vừa có văn b...      0   \n",
       "\n",
       "                                        encoded_caption  \\\n",
       "464   [[tensor(-0.3261), tensor(0.1561), tensor(-0.0...   \n",
       "7413  [[tensor(-0.1268), tensor(-0.0320), tensor(-0....   \n",
       "3808  [[tensor(-0.1112), tensor(0.0278), tensor(-0.0...   \n",
       "5816  [[tensor(0.0312), tensor(0.0544), tensor(-0.21...   \n",
       "1632  [[tensor(-0.0825), tensor(0.1394), tensor(-0.0...   \n",
       "\n",
       "                                         extracted_text  \\\n",
       "464   VỢ CHỔNG THUỶ TIÊN, CÔNG VINH ĐI CHOI PHÚ QUỐC...   \n",
       "7413  Jz mấy má? 29 phút trước Học lý 12 không hiểu ...   \n",
       "3808                                                      \n",
       "5816   ĐÃ BlẾT ĐUỢC LÍ DO LỆ KWEEN KHÔNG UA TRANG PARIS   \n",
       "1632  Đà Nẵng: Cẩu Rông dừng phun cầu sông Hàn không...   \n",
       "\n",
       "                                 encoded_extracted_text  \\\n",
       "464   [[tensor(-0.2914), tensor(0.2022), tensor(-0.1...   \n",
       "7413  [[tensor(-0.1801), tensor(0.1206), tensor(-0.0...   \n",
       "3808  [[tensor(0.1059), tensor(0.6111), tensor(-0.26...   \n",
       "5816  [[tensor(-0.0723), tensor(0.1501), tensor(-0.2...   \n",
       "1632  [[tensor(-0.0106), tensor(0.2360), tensor(-0.2...   \n",
       "\n",
       "                                          combined_text  \\\n",
       "464   [[tensor(-0.3261), tensor(0.1561), tensor(-0.0...   \n",
       "7413  [[tensor(-0.1268), tensor(-0.0320), tensor(-0....   \n",
       "3808  [[tensor(-0.1112), tensor(0.0278), tensor(-0.0...   \n",
       "5816  [[tensor(0.0312), tensor(0.0544), tensor(-0.21...   \n",
       "1632  [[tensor(-0.0825), tensor(0.1394), tensor(-0.0...   \n",
       "\n",
       "                                          encoded_image  \n",
       "464   [[tensor(-0.2019, device='cuda:0', dtype=torch...  \n",
       "7413  [[tensor(-0.1495, device='cuda:0', dtype=torch...  \n",
       "3808  [[tensor(-0.0428, device='cuda:0', dtype=torch...  \n",
       "5816  [[tensor(-0.0614, device='cuda:0', dtype=torch...  \n",
       "1632  [[tensor(-0.1697, device='cuda:0', dtype=torch...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['encoded_caption'] = df['caption'].apply(encode_text)\n",
    "df['extracted_text'] = df['image'].apply(lambda x: extract_text_from_image(x, 'warmup'))\n",
    "df['encoded_extracted_text'] = df['extracted_text'].apply(encode_text)\n",
    "df['combined_text'] = df.apply(concat_tensors, axis=1)\n",
    "df['encoded_image'] = df['image'].apply(lambda x: encode_image(x, 'warmup'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 512\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "image_transform = ImageTransform(resize, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasmDataset(Dataset): \n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        \n",
    "        ret = {\n",
    "            'image_features': row['encoded_image'].float(),\n",
    "            'caption_features': row['encoded_caption'].float(),\n",
    "            'extracted_text_features': row['encoded_extracted_text'],\n",
    "            'label': row['label']\n",
    "        }\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tạo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_caption</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>encoded_extracted_text</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>encoded_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>724743746f3fe695cd93cab67abf47f31348dd46e1d6e8...</td>\n",
       "      <td>Biển miền Trung nước đẹp nhỉ</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(-0.3261), tensor(0.1561), tensor(-0.0...</td>\n",
       "      <td>VỢ CHỔNG THUỶ TIÊN, CÔNG VINH ĐI CHOI PHÚ QUỐC...</td>\n",
       "      <td>[[tensor(-0.2914), tensor(0.2022), tensor(-0.1...</td>\n",
       "      <td>[[tensor(-0.3261), tensor(0.1561), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.2019, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7413</th>\n",
       "      <td>92d5d63ece4471fa20fda5a504b841f17eaee8172de711...</td>\n",
       "      <td>Chắc là nắc cụt rồi\\n#phetphaikhong</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(-0.1268), tensor(-0.0320), tensor(-0....</td>\n",
       "      <td>Jz mấy má? 29 phút trước Học lý 12 không hiểu ...</td>\n",
       "      <td>[[tensor(-0.1801), tensor(0.1206), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.1268), tensor(-0.0320), tensor(-0....</td>\n",
       "      <td>[[tensor(-0.1495, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>abadbf508db12242d4f00f69ac690305e91dc5d8ad0c07...</td>\n",
       "      <td>Nhiều khi ta muốn ta được thiếu nợ\\nĐể khi đi ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.1112), tensor(0.0278), tensor(-0.0...</td>\n",
       "      <td></td>\n",
       "      <td>[[tensor(0.1059), tensor(0.6111), tensor(-0.26...</td>\n",
       "      <td>[[tensor(-0.1112), tensor(0.0278), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.0428, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5816</th>\n",
       "      <td>84a61e90daadb2297888d685299e25a00a03a91515059b...</td>\n",
       "      <td>Phi công này 1 người lái thôi, ai đụng vào là ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(0.0312), tensor(0.0544), tensor(-0.21...</td>\n",
       "      <td>ĐÃ BlẾT ĐUỢC LÍ DO LỆ KWEEN KHÔNG UA TRANG PARIS</td>\n",
       "      <td>[[tensor(-0.0723), tensor(0.1501), tensor(-0.2...</td>\n",
       "      <td>[[tensor(0.0312), tensor(0.0544), tensor(-0.21...</td>\n",
       "      <td>[[tensor(-0.0614, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>cf50dca40e9196eb443a4b33db60c17c5ad2da69726aab...</td>\n",
       "      <td>Ủy ban Nhân dân thành phố Đà Nẵng vừa có văn b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.0825), tensor(0.1394), tensor(-0.0...</td>\n",
       "      <td>Đà Nẵng: Cẩu Rông dừng phun cầu sông Hàn không...</td>\n",
       "      <td>[[tensor(-0.0106), tensor(0.2360), tensor(-0.2...</td>\n",
       "      <td>[[tensor(-0.0825), tensor(0.1394), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.1697, device='cuda:0', dtype=torch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  \\\n",
       "464   724743746f3fe695cd93cab67abf47f31348dd46e1d6e8...   \n",
       "7413  92d5d63ece4471fa20fda5a504b841f17eaee8172de711...   \n",
       "3808  abadbf508db12242d4f00f69ac690305e91dc5d8ad0c07...   \n",
       "5816  84a61e90daadb2297888d685299e25a00a03a91515059b...   \n",
       "1632  cf50dca40e9196eb443a4b33db60c17c5ad2da69726aab...   \n",
       "\n",
       "                                                caption  label  \\\n",
       "464                        Biển miền Trung nước đẹp nhỉ      3   \n",
       "7413                Chắc là nắc cụt rồi\\n#phetphaikhong      3   \n",
       "3808  Nhiều khi ta muốn ta được thiếu nợ\\nĐể khi đi ...      0   \n",
       "5816  Phi công này 1 người lái thôi, ai đụng vào là ...      3   \n",
       "1632  Ủy ban Nhân dân thành phố Đà Nẵng vừa có văn b...      0   \n",
       "\n",
       "                                        encoded_caption  \\\n",
       "464   [[tensor(-0.3261), tensor(0.1561), tensor(-0.0...   \n",
       "7413  [[tensor(-0.1268), tensor(-0.0320), tensor(-0....   \n",
       "3808  [[tensor(-0.1112), tensor(0.0278), tensor(-0.0...   \n",
       "5816  [[tensor(0.0312), tensor(0.0544), tensor(-0.21...   \n",
       "1632  [[tensor(-0.0825), tensor(0.1394), tensor(-0.0...   \n",
       "\n",
       "                                         extracted_text  \\\n",
       "464   VỢ CHỔNG THUỶ TIÊN, CÔNG VINH ĐI CHOI PHÚ QUỐC...   \n",
       "7413  Jz mấy má? 29 phút trước Học lý 12 không hiểu ...   \n",
       "3808                                                      \n",
       "5816   ĐÃ BlẾT ĐUỢC LÍ DO LỆ KWEEN KHÔNG UA TRANG PARIS   \n",
       "1632  Đà Nẵng: Cẩu Rông dừng phun cầu sông Hàn không...   \n",
       "\n",
       "                                 encoded_extracted_text  \\\n",
       "464   [[tensor(-0.2914), tensor(0.2022), tensor(-0.1...   \n",
       "7413  [[tensor(-0.1801), tensor(0.1206), tensor(-0.0...   \n",
       "3808  [[tensor(0.1059), tensor(0.6111), tensor(-0.26...   \n",
       "5816  [[tensor(-0.0723), tensor(0.1501), tensor(-0.2...   \n",
       "1632  [[tensor(-0.0106), tensor(0.2360), tensor(-0.2...   \n",
       "\n",
       "                                          combined_text  \\\n",
       "464   [[tensor(-0.3261), tensor(0.1561), tensor(-0.0...   \n",
       "7413  [[tensor(-0.1268), tensor(-0.0320), tensor(-0....   \n",
       "3808  [[tensor(-0.1112), tensor(0.0278), tensor(-0.0...   \n",
       "5816  [[tensor(0.0312), tensor(0.0544), tensor(-0.21...   \n",
       "1632  [[tensor(-0.0825), tensor(0.1394), tensor(-0.0...   \n",
       "\n",
       "                                          encoded_image  \n",
       "464   [[tensor(-0.2019, device='cuda:0', dtype=torch...  \n",
       "7413  [[tensor(-0.1495, device='cuda:0', dtype=torch...  \n",
       "3808  [[tensor(-0.0428, device='cuda:0', dtype=torch...  \n",
       "5816  [[tensor(-0.0614, device='cuda:0', dtype=torch...  \n",
       "1632  [[tensor(-0.1697, device='cuda:0', dtype=torch...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo dataset\n",
    "train_dataset = SarcasmDataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tạo Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasmClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SarcasmClassifier, self).__init__()\n",
    "        self.fc_image = nn.Linear(512, 512)\n",
    "        self.fc_caption = nn.Linear(768, 512)\n",
    "        self.fc1 = nn.Linear(512 * 2, 256)  # Combine both inputs\n",
    "        self.fc2 = nn.Linear(256, 4)  # 4 classification labels\n",
    "        \n",
    "        # Additional layers for better performance\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, image_features, caption_features):\n",
    "        image_features = F.relu(self.fc_image(image_features))\n",
    "        image_features = self.batch_norm1(image_features)\n",
    "        \n",
    "        caption_features = F.relu(self.fc_caption(caption_features))\n",
    "        caption_features = self.batch_norm1(caption_features)\n",
    "        \n",
    "        combined_features = torch.cat((image_features, caption_features), dim=1)\n",
    "        combined_features = F.relu(self.fc1(combined_features))\n",
    "        combined_features = self.batch_norm2(combined_features)\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        \n",
    "        output = self.fc2(combined_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 64.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.1972186863422394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 179.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.7683773040771484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 160.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.613918624818325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 186.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.47284547984600067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 181.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.3723446913063526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình, loss function và optimizer\n",
    "model = SarcasmClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "# Huấn luyện mô hình\n",
    "for epoch in range(num_epochs):  # Huấn luyện trong 5 epoch\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        image_features = batch['image_features'].to(device)\n",
    "        caption_features = batch['caption_features'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(image_features, caption_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/5], Loss: {epoch_loss / len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.06%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in train_dataloader:\n",
    "        image_features = batch['image_features'].to(device)\n",
    "        caption_features = batch['caption_features'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(image_features, caption_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sarcasm_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin!\\AppData\\Local\\Temp\\ipykernel_19580\\2559104630.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('sarcasm_classifier.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SarcasmClassifier(\n",
       "  (fc_image): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc_caption): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SarcasmClassifier().to(device)\n",
    "model.load_state_dict(torch.load('sarcasm_classifier.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_json('vimmsd-warmup.json')\n",
    "\n",
    "test_df = test_df.T\n",
    "\n",
    "test_df['encoded_caption'] = test_df['caption'].apply(encode_text)\n",
    "test_df['extracted_text'] = test_df['image'].apply(lambda x: extract_text_from_image(x, 'warmup'))\n",
    "test_df['encoded_extracted_text'] = test_df['extracted_text'].apply(encode_text)\n",
    "test_df['combined_text'] = test_df.apply(concat_tensors, axis=1)\n",
    "test_df['encoded_image'] = test_df['image'].apply(lambda x: encode_image(x, 'warmup'))\n",
    "\n",
    "test_dataset = SarcasmDataset(test_df)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 196.66it/s]\n"
     ]
    }
   ],
   "source": [
    "label_map = {0: \"not-sarcasm\", 1: \"image-sarcasm\", 2: \"text-sarcasm\", 3: \"multi-sarcasm\"}\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        image_features = batch['image_features'].to(device)\n",
    "        caption_features = batch['caption_features'].to(device)\n",
    "        \n",
    "        outputs = model(image_features, caption_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "predictions = [label_map[p] for p in predictions]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
